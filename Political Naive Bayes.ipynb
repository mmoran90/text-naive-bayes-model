{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and libraries\n",
    "import sqlite3\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "# from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to database\n",
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', 'Democratic'], ['Every four years, we come together to reaffirm our democracy. This year, we’ve come to save it.', 'Democratic'], ['We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.', 'Democratic'], ['We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "# Query to pull data and exclude 'Other' party\n",
    "query = '''\n",
    "    SELECT text, party\n",
    "    FROM conventions\n",
    "    WHERE party != 'Other'\n",
    "'''\n",
    "\n",
    "# Execute the query and fetch all the data\n",
    "query_results = convention_cur.execute(query).fetchall()\n",
    "\n",
    "# Initialize the list to store results\n",
    "convention_data = [[row[0], row[1]] for row in query_results]\n",
    "\n",
    "# Close the database connection\n",
    "convention_db.close()\n",
    "\n",
    "# Print only a few records from the convention_data for verification\n",
    "print(convention_data[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Then this bold man comes down the escalator in New York City. I couldn’t come out and say it right away, but deep down inside, I knew it was going to be the first Republican that I ever voted for.',\n",
       "  'Republican'],\n",
       " ['Our official roll call and the business of our Republican convention was conducted today in Charlotte. We have created a short video to symbolize the excitement for President Trump across all 50 states and territories. Thank you for watching. God bless you and God bless the United States of America.',\n",
       "  'Republican'],\n",
       " ['Kentucky.', 'Republican'],\n",
       " ['China would prefer Joe Biden.', 'Republican'],\n",
       " ['That was so sweet with the grandkids. Yay. And now we have an official nominee. Onto the next step. Electing Joe Biden and Kamala Harris in November. Make sure you have a plan to vote. Text vote to 30330 to find out how. Now we’re going to talk about a topic that touches all of our lives. Healthcare. The Affordable Care Act was game-changing. This pandemic has revealed just how important it is to protect and improve it. Increasing access to healthcare and bringing down its cost have always been a priority for Joe Biden, because for Joe, and for all of us, healthcare is personal.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print random entries from database\n",
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20.', 'Democratic'], ['Read the full transcript of the event here.', 'Democratic'], ['Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order.', 'Democratic'], ['Welcome all to our final session of this historic and memorable convention.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list to store individual sentences\n",
    "conv_sent_data = []\n",
    "\n",
    "# Process each speech in convention_data and split it into sentences using regex\n",
    "for row in convention_data:\n",
    "    speech_text, party = row\n",
    "    sentences = re.split(r'(?<=[.!?]) +', speech_text)\n",
    "    for sentence in sentences:\n",
    "        conv_sent_data.append([sentence, party])\n",
    "\n",
    "# Step 2: Print only a few records from conv_sent_data for verification\n",
    "print(conv_sent_data[:5]) \n",
    "\n",
    "# I had various troubles using nltk in VS Code and Jupyter, so i decided to use Python re instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['30330, that would be the president’s golf score if he didn’t cheat.',\n",
       "  'Democratic'],\n",
       " ['Donald Trump believed in me when I was a teenage golf caddy and he was already one of the wealthiest, most famous people on the entire planet.',\n",
       "  'Republican'],\n",
       " ['While the hurricane was fierce, one of the strongest to make landfall in 150 years, the casualties and damage were far less than thought possible only 24 hours ago.',\n",
       "  'Republican'],\n",
       " ['President Trump is bringing this country back roaring.', 'Republican'],\n",
       " ['There are battles that we need to fight and we need to win to secure our future in this country, but there’s one issue that is an existential threat to all of us and that is climate change)',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print random selections\n",
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('every', 'Democratic'), ('common sense goals hopes believe', 'Republican'), ('knowing change vote leaders think make', 'Democratic'), ('imagine like going sleep wondering', 'Democratic'), ('samuel even told life worth', 'Republican')]\n"
     ]
    }
   ],
   "source": [
    "# Define stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = string.punctuation\n",
    "\n",
    "# Initialize the list to store cleaned sentences\n",
    "clean_conv_sent_data = []\n",
    "\n",
    "# Process each sentence in conv_sent_data\n",
    "for idx, sent_party in enumerate(conv_sent_data):\n",
    "    sentence, party = sent_party\n",
    "    tokens = sentence.split()\n",
    "    cleaned_tokens = [\n",
    "        token.casefold() for token in tokens\n",
    "        if token.isalpha() and token.casefold() not in stop_words\n",
    "    ]\n",
    "    # Join the remaining tokens into a string\n",
    "    cleaned_sentence = ' '.join(cleaned_tokens)\n",
    "    if cleaned_sentence:  # Only add if the cleaned sentence is not empty\n",
    "        clean_conv_sent_data.append((cleaned_sentence, party))\n",
    "\n",
    "# Print 5 random records from clean_conv_sent_data for verification\n",
    "print(random.choices(clean_conv_sent_data, k=5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 1776 words as features in the model.\n"
     ]
    }
   ],
   "source": [
    "# Set the word frequency cutoff\n",
    "word_cutoff = 5\n",
    "\n",
    "# Get all tokens from clean_conv_sent_data\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "# Calculate word frequency distribution\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "# Identify feature words based on the cutoff\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items():\n",
    "    if count > word_cutoff:\n",
    "        feature_words.add(word)\n",
    "\n",
    "# Print the number of feature words\n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} words as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract features from text\n",
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the text on whitespace and convert it to a set of words\n",
    "    tokens = set(text.casefold().split())\n",
    "\n",
    "    # Create a dictionary for the feature words\n",
    "    ret_dict = {word: True for word in tokens if word in fw}\n",
    "    \n",
    "    # Return dictionary\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All assertions passed!\n"
     ]
    }
   ],
   "source": [
    "# Assertion to make sure feature_words is not empty\n",
    "assert(len(feature_words)>0)\n",
    "\n",
    "# Assertion to make sure the target words in quotations are identified as features\n",
    "assert(conv_features(\"obama was the president\",feature_words)==\n",
    "       {'obama':True,'president':True})\n",
    "\n",
    "# Assertion to make sure the target words in quotations are identified as features\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})\n",
    "\n",
    "print(\"All assertions passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of tuples with feature dictionaries with corresponding party label\n",
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "random.seed(20220507)\n",
    "\n",
    "# Set random shuffle to ensure that the training and test data are randomly distributed\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "# Define test size\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.502\n"
     ]
    }
   ],
   "source": [
    "# Define test and train data\n",
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "\n",
    "# Train Naive classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Print classifier accuracy\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   china = True           Republ : Democr =     26.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
      "                supports = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
      "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
      "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                 private = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "                 special = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
      "                   trade = True           Republ : Democr =     10.5 : 1.0\n",
      "                 sanders = True           Democr : Republ =     10.1 : 1.0\n",
      "                   armed = True           Republ : Democr =      9.9 : 1.0\n",
      "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
      "                 liberal = True           Republ : Democr =      9.9 : 1.0\n",
      "                veterans = True           Republ : Democr =      9.9 : 1.0\n",
      "               wonderful = True           Republ : Democr =      9.9 : 1.0\n",
      "                 allowed = True           Republ : Democr =      9.7 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print 25 most informative features used by the classifier.\n",
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "Based on the classifier's most informative features, I can see some clear distinctions in the language used by Republican and Democratic speakers. I believe these to align very well with the themes and priorities of each party. For instance, Republicans use more firmer words such as \"enforcement,\" \"china,\" \"media,\" \"freedoms,\" \"private,\" and \"amendment\". This suggests that Republicans frequently emphasize themes like law enforcement, national security, individual freedoms, and media issues. On the other hand, democrats tend to use a bit softer words such as \"climate,\" \"votes,\" \"elect,\" \"sanders,\" and \"america\". This indicates that climate change is a key issue for Democrats, as expected. The presence of \"votes\" and \"elect\" suggests a focus on electoral participation and democracy, which is often a major theme during Democratic conventions and campaigns.\n",
    "\n",
    "Both parties also tend to place an emphasis on personalities, like \"sanders\" by Democrats and \"abraham\" by Replublicans. I believe these are used by each party to strengthen their message using historical figures. Polarizing themes also become pretty evident, justified by words such as \"defund\" (Republicans) or \"climate\" (Democrats). Based on opposing views of each party, this is definitely not a susprise. Finally, the ratio values (e.g., 27.5 : 1.0 for \"enforcement\") suggest that certain words are extremely indicative of a party affiliation. These high ratios imply that some terms are rarely, if ever, used by the opposing party, demonstrating a clear division in the rhetoric or topics discussed by each party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection to database\n",
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "\n",
    "# Configure cursor\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "# Results in lists\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mo Brooks', 'Republican', b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq'), ('Mo Brooks', 'Republican', b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6'), ('Mo Brooks', 'Republican', b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA')]\n"
     ]
    }
   ],
   "source": [
    "# Verify a few results from query\n",
    "print(results[:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq', 'Republican'], [b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6', 'Republican'], [b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA', 'Republican'], [b'\"The trouble with Socialism is that eventually you run out of other people\\'s money.\" - Margaret Thatcher https://t.co/X97g7wzQwJ', 'Republican'], [b'\"The trouble with socialism is eventually you run out of other people\\'s money\" \\xe2\\x80\\x93 Thatcher. She\\'ll be sorely missed. http://t.co/Z8gBnDQUh8', 'Republican']]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list to store tweet data\n",
    "tweet_data = []\n",
    "\n",
    "# Iterate through the query results\n",
    "for row in results:\n",
    "    candidate, party, tweet_text = row\n",
    "    tweet_data.append([tweet_text, party])\n",
    "\n",
    "# Print only a few records from tweet_data for verification\n",
    "print(tweet_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(20201014)\n",
    "\n",
    "# Take random sample\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier spoke house floor abt protecting health care women praised work central\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: trump thinks easy students overwhelmed crushing burden debt pay student loans\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first rescue volunteers working tirelessly keep people provide putting lives\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: make even greater\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: tie series\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats new gig sd city glad continue\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really raised toward match right majors room help us get\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: comment period plan expand offshore drilling opened days march share oppose proposed program directly trump comments made email\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated years eastside commitment saluted community leaders last awards\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update clean_text to handle byte strings\n",
    "def clean_text(text):\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode('utf-8')\n",
    "        \n",
    "    # Tokenize on whitespace and convert to lowercase\n",
    "    tokens = text.casefold().split()\n",
    "    # Remove punctuation, non-alphabetic tokens, stopwords\n",
    "    cleaned_tokens = [\n",
    "        token for token in tokens\n",
    "        if token.isalpha() and token not in stop_words\n",
    "    ]\n",
    "    # Join tokens back into a single cleaned string\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Loop through each tweet in the sample\n",
    "for tweet, party in tweet_data_sample:\n",
    "    cleaned_tweet = clean_text(tweet)\n",
    "    \n",
    "    # Convert cleaned tweet to feature dictionary\n",
    "    tweet_features = conv_features(cleaned_tweet, feature_words)\n",
    "    \n",
    "    # Use the classifier to estimate the party\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Here's our (cleaned) tweet: {cleaned_tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Republican, Estimated: Republican, Count: 3540\n",
      "Actual: Republican, Estimated: Democratic, Count: 767\n",
      "Actual: Democratic, Estimated: Republican, Count: 4564\n",
      "Actual: Democratic, Estimated: Democratic, Count: 1130\n"
     ]
    }
   ],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Initialize the dictionary with counts set to zero\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "# Number of tweets to classify\n",
    "num_to_score = 10000\n",
    "\n",
    "# Shuffle tweet_data for random sampling\n",
    "random.seed(20220507)\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "# Classify tweets and store results\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, actual_party = tp\n",
    "    \n",
    "    # Clean the tweet text\n",
    "    cleaned_tweet = clean_text(tweet)\n",
    "    \n",
    "    # Convert cleaned tweet to feature dictionary\n",
    "    tweet_features = conv_features(cleaned_tweet, feature_words)\n",
    "    \n",
    "    # Estimate the party using the classifier\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "    \n",
    "    # Increment the count in the results dictionary\n",
    "    results[actual_party][estimated_party] += 1\n",
    "    \n",
    "    # Stop after scoring the specified number of tweets\n",
    "    if idx >= num_to_score:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "for actual in parties:\n",
    "    for estimated in parties:\n",
    "        print(f\"Actual: {actual}, Estimated: {estimated}, Count: {results[actual][estimated]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3540  767]\n",
      " [4564 1130]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the counts from the results dictionary\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Populate the lists with true and predicted labels based on the counts in results\n",
    "for actual_party in parties:\n",
    "    for estimated_party in parties:\n",
    "        count = results[actual_party][estimated_party]\n",
    "        y_true.extend([actual_party] * count)\n",
    "        y_pred.extend([estimated_party] * count)\n",
    "\n",
    "# Create a simple confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=['Republican', 'Democratic'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "Based on the results, I can conclude that the Naive classifier is only slightly better than random guessing. Specifically, 46.7% better noted by the model's accuracy. Also, the high recall for Republican (82.2%) but low precision (43.7%) indicates that the classifier is good at finding Republican tweets, but it often incorrectly labels Democratic tweets as Republican. The low recall for Democratic (19.8%) suggests that the classifier is struggling significantly to correctly identify Democratic tweets.\n",
    "\n",
    "In essence, it seems that the classifier might be biased towards predicting \"Republican\" more often, possibly because of an imbalance in the data or because the feature words are more representative of Republican language. It might be worth revisiting the features or trying to balance the dataset to improve the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
